defmodule PacketFlow.ExecutionEngine do
  @moduledoc """
  Execution engine for PacketFlow capabilities and AI-generated plans.

  Handles execution of individual capabilities and orchestration of complex
  multi-step plans generated by the AI planner.
  """

  use GenServer
  require Logger

  # Public API

  def start_link(opts \\ []) do
    GenServer.start_link(__MODULE__, opts, name: __MODULE__)
  end

  @doc """
  Execute a single capability by ID.
  """
  def execute(capability_id, payload, context \\ %{}) do
    GenServer.call(__MODULE__, {:execute_capability, capability_id, payload, context}, 60_000)
  end

  @doc """
  Execute a complete AI-generated plan.
  """
  def execute_plan(plan, initial_payload, context \\ %{}) do
    GenServer.call(__MODULE__, {:execute_plan, plan, initial_payload, context}, 60_000)
  end

  @doc """
  Get execution status for a running plan.
  """
  def get_execution_status(execution_id) do
    GenServer.call(__MODULE__, {:get_status, execution_id})
  end

  # GenServer implementation

  @impl true
  def init(_opts) do
    # ETS table to track running executions
    :ets.new(:packet_flow_executions, [:named_table, :public, :set])

    Logger.info("PacketFlow.ExecutionEngine started")
    {:ok, %{}}
  end

  @impl true
  def handle_call({:execute_capability, capability_id, payload, context}, _from, state) do
    execution_id = generate_execution_id()

    result = execute_single_capability(capability_id, payload, context, execution_id)

    {:reply, result, state}
  end

  @impl true
  def handle_call({:execute_plan, plan, initial_payload, context}, _from, state) do
    execution_id = generate_execution_id()

    # Store execution metadata
    execution_meta = %{
      id: execution_id,
      plan: plan,
      status: :running,
      started_at: DateTime.utc_now(),
      steps_completed: 0,
      total_steps: length(plan["execution_plan"]["steps"]),
      context: context
    }

    :ets.insert(:packet_flow_executions, {execution_id, execution_meta})

    # Execute the plan
    result = execute_plan_steps(plan, initial_payload, context, execution_id)

    # Update final status
    final_meta = Map.merge(execution_meta, %{
      status: case result do
        {:ok, _} -> :completed
        {:error, _} -> :failed
      end,
      completed_at: DateTime.utc_now()
    })

    :ets.insert(:packet_flow_executions, {execution_id, final_meta})

    {:reply, Map.put(result, :execution_id, execution_id), state}
  end

  @impl true
  def handle_call({:get_status, execution_id}, _from, state) do
    case :ets.lookup(:packet_flow_executions, execution_id) do
      [{^execution_id, meta}] -> {:reply, {:ok, meta}, state}
      [] -> {:reply, {:error, :execution_not_found}, state}
    end
  end

  # Private functions

  defp generate_execution_id do
    :crypto.strong_rand_bytes(16) |> Base.encode16(case: :lower)
  end

  defp execute_single_capability(capability_id, payload, context, execution_id) do
    # Add execution tracking to context
    enhanced_context = Map.merge(context, %{
      execution_id: execution_id,
      capability_id: capability_id,
      started_at: DateTime.utc_now()
    })

    case PacketFlow.CapabilityRegistry.get_capability(capability_id) do
      {:ok, capability_meta} ->
        execute_capability_function(capability_meta, payload, enhanced_context)

      {:error, :not_found} ->
        Logger.error("Capability not found: #{capability_id}")
        {:error, {:capability_not_found, capability_id}}
    end
  end

  defp execute_capability_function(capability_meta, payload, context) do
    try do
            # Call the capability function on the module
      module = capability_meta.module
      capability_id = capability_meta.id

      Logger.info("Executing capability #{capability_id} on module #{module}")

      # Add telemetry
      :telemetry.execute(
        [:packet_flow, :capability, :start],
        %{},
        %{capability_id: capability_id, module: module}
      )

      start_time = System.monotonic_time(:microsecond)

      # Call the capability function
      result = apply(module, capability_id, [payload, context])

      end_time = System.monotonic_time(:microsecond)
      duration = end_time - start_time

      # Emit telemetry
      :telemetry.execute(
        [:packet_flow, :capability, :stop],
        %{duration: duration},
        %{capability_id: capability_id, module: module, result: result}
      )

      Logger.info("Capability #{capability_id} completed in #{duration}Î¼s")

      result
    rescue
      error ->
        Logger.error("Capability execution failed: #{inspect(error)}")

        :telemetry.execute(
          [:packet_flow, :capability, :error],
          %{},
          %{capability_id: capability_meta.id, error: error}
        )

        {:error, {:execution_failed, error}}
    end
  end

  defp execute_plan_steps(plan, initial_payload, context, execution_id) do
    steps = plan["execution_plan"]["steps"]
    plan_type = plan["execution_plan"]["type"]

    case plan_type do
      "sequential" -> execute_sequential_steps(steps, initial_payload, context, execution_id)
      "parallel" -> execute_parallel_steps(steps, initial_payload, context, execution_id)
      "conditional" -> execute_conditional_steps(steps, initial_payload, context, execution_id)
      _ -> execute_sequential_steps(steps, initial_payload, context, execution_id)
    end
  end

  defp execute_sequential_steps(steps, initial_payload, context, execution_id) do
    Logger.info("Executing #{length(steps)} sequential steps for execution #{execution_id}")

    {final_result, _final_payload} =
      Enum.reduce_while(steps, {:ok, initial_payload}, fn step, {_status, accumulated_payload} ->
        step_result = execute_plan_step(step, accumulated_payload, context, execution_id)

        case step_result do
          {:ok, step_output} ->
            # Merge step output with accumulated payload
            merged_payload = Map.merge(accumulated_payload, step_output)
            update_execution_progress(execution_id)
            {:cont, {:ok, merged_payload}}

          {:error, reason} ->
            Logger.error("Step #{step["id"]} failed: #{inspect(reason)}")
            {:halt, {:error, {:step_failed, step["id"], reason}}}
        end
      end)

    final_result
  end

  defp execute_parallel_steps(steps, initial_payload, context, execution_id) do
    Logger.info("Executing #{length(steps)} parallel steps for execution #{execution_id}")

    # Execute all steps in parallel
    tasks = Enum.map(steps, fn step ->
      Task.async(fn ->
        {step["id"], execute_plan_step(step, initial_payload, context, execution_id)}
      end)
    end)

    # Wait for all tasks to complete
    results = Task.await_many(tasks, 30_000)

    # Check if any failed
    failed_steps = Enum.filter(results, fn {_step_id, result} ->
      match?({:error, _}, result)
    end)

    if Enum.empty?(failed_steps) do
      # Combine all successful results
      combined_output = results
      |> Enum.reduce(%{}, fn {step_id, {:ok, output}}, acc ->
        Map.merge(acc, output)
      end)

      update_execution_progress(execution_id, length(steps))
      {:ok, combined_output}
    else
      Logger.error("Parallel execution failed. Failed steps: #{inspect(failed_steps)}")
      {:error, {:parallel_execution_failed, failed_steps}}
    end
  end

  defp execute_conditional_steps(steps, initial_payload, context, execution_id) do
    # For now, treat conditional as sequential
    # TODO: Implement proper conditional logic based on step conditions
    execute_sequential_steps(steps, initial_payload, context, execution_id)
  end

  defp execute_plan_step(step, payload, context, execution_id) do
    capability_id = String.to_atom(step["capability_id"])
    step_inputs = Map.get(step, "inputs", %{})

    # Merge step inputs with current payload
    step_payload = Map.merge(payload, step_inputs)

    # Add step context
    step_context = Map.merge(context, %{
      step_id: step["id"],
      step_description: step["description"],
      execution_id: execution_id
    })

    Logger.info("Executing step #{step["id"]}: #{step["description"]}")

    execute_single_capability(capability_id, step_payload, step_context, execution_id)
  end

  defp update_execution_progress(execution_id, steps_increment \\ 1) do
    case :ets.lookup(:packet_flow_executions, execution_id) do
      [{^execution_id, meta}] ->
        updated_meta = Map.update(meta, :steps_completed, steps_increment, &(&1 + steps_increment))
        :ets.insert(:packet_flow_executions, {execution_id, updated_meta})

      [] ->
        Logger.warn("Execution metadata not found for #{execution_id}")
    end
  end
end
